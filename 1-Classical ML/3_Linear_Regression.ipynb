{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/ml_ad_ai_course/blob/main/Classical%20ML/3_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJAcPro111rk"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "Â© Data Trainers LLC. GPL v 3.0.\n",
        "\n",
        "Author: Axel Sirota"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AxMIZFl11rl"
      },
      "source": [
        "#### Learning Objectives\n",
        "- Define data modeling and simple linear regression.\n",
        "- Build a linear regression model\n",
        "- Understand and identify multicollinearity in a multiple regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LncCLxaT11rm"
      },
      "source": [
        "<a id=\"introduce-the-bikeshare-dataset\"></a>\n",
        "## Bikeshare Data Set\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHOyyizb11rn"
      },
      "source": [
        "We'll be working with a data set from Capital Bikeshare that was used in a Kaggle competition ([data dictionary](https://www.kaggle.com/c/bike-sharing-demand/data)).\n",
        "\n",
        "The objective of the competition is to predict total ridership of Capital Bikeshare in any given hour.\n",
        "\n",
        "Demand forecasting is a common data science application. If we can predict the quantity of demand, total ridership in a given hour, we can create analytical tools to improve the bikeshare system.\n",
        "Some applications would be:\n",
        "* Find where to site new bikeshare stations and know how large of a station to build.\n",
        "* Calculate the expected wear and tear on bikes and what the replacement costs will be.\n",
        "* Use a slightly different research design to forecast full and empty stations and send a service vehicle to \"rebalance\" the bikes from one station to another, as sometimes bikeshare stations have no bikes or are completely full and prevent use of the station.\n",
        "\n",
        "Businesses aren't new to demand forecasting, but older methods suffered from poor predictions at atypical small locations. Modern approaches incorporate clusters and online data from Twitter and Google Trends to improve prediction in these small locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTbuvvQi11rn"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaqsMXKU11ro"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.rcParams['font.size'] = 14\n",
        "plt.style.use(\"fivethirtyeight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckL8FJTl11rp"
      },
      "source": [
        "<a id=\"read-in-the--capital-bikeshare-data\"></a>\n",
        "### Read In the Capital Bikeshare Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "mkdir -p data\n",
        "if [ ! -f data/bikeshare.csv ]; then\n",
        "  wget -O data/bikeshare.csv https://www.dropbox.com/scl/fi/pqg3wpt5e1ltjyrk1ty6e/bikeshare.csv?rlkey=fnv6jbytx723ax6orgegg0pj6&dl=0\n",
        "fi\n",
        "if [ ! -f data/sacramento.csv ]; then\n",
        "  wget -O data/sacramento.csv https://www.dropbox.com/scl/fi/cfw173th70cnhxcf391bg/sacramento_real_estate_transactions.csv?rlkey=frcssm4tdjf0xrtlwnj5znm2n&dl=0\n",
        "fi\n"
      ],
      "metadata": {
        "id": "v_M2GMx_40AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh"
      ],
      "metadata": {
        "id": "8LQSAoxd90lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrIXBPoN11rq"
      },
      "outputs": [],
      "source": [
        "# Read the data and set the datetime as the index.\n",
        "url = './data/bikeshare.csv'\n",
        "bikes = pd.read_csv(url, index_col='datetime', parse_dates=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIyVmcfZ11rq"
      },
      "source": [
        "Notice that we used `index_col` to set an index or primary key for our data. In this case, the index of each row will be set to the value of its `datetime` field.\n",
        "\n",
        "We also ask Pandas to parse dates (if `parse_dates=True`, for the index only). So, rather than reading in a string, Pandas converts the index string to a `datetime` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2ztWW-lz11rr"
      },
      "outputs": [],
      "source": [
        "# Preview the first five rows of the DataFrame.\n",
        "bikes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaHtdxMj11rs"
      },
      "source": [
        "#### How many features are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAVPe7r_11rs"
      },
      "outputs": [],
      "source": [
        "# A:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6VYwso11rt"
      },
      "source": [
        "| Variable| Description |\n",
        "|---------|----------------|\n",
        "|datetime| hourly date + timestamp  |\n",
        "|season|  1=winter, 2=spring, 3=summer, 4=fall |\n",
        "|holiday| whether the day is considered a holiday|\n",
        "|workingday| whether the day is neither a weekend nor holiday|\n",
        "|weather| See Below|\n",
        "|temp| temperature in Celsius|\n",
        "|atemp| \"feels like\" temperature in Celsius|\n",
        "|humidity| relative humidity|\n",
        "|windspeed| wind speed|\n",
        "|casual| number of non-registered user rentals initiated|\n",
        "|registered| number of registered user rentals initiated|\n",
        "|count| number of total rentals|\n",
        "\n",
        "> _Details on Weather Variable_\n",
        "\n",
        "> **1**: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "\n",
        "> **2**: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "\n",
        "> **3**: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "\n",
        "> **4**: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoKbxMcO11rt"
      },
      "source": [
        "#### \"count\" is a method in Pandas (and a very non-specific name), so it's best to name that column something else\n",
        "\n",
        "In general, you may want to rename columns if it is not obvious what might be stored in them. Although we will only rename the target column here, a few examples might be to rename:\n",
        "\n",
        "| old name | new name |\n",
        "| ---    | --- |\n",
        "| temp | temp_celcius\n",
        "| windspeed | windspeed_knots\n",
        "| casual | num_casual_users\n",
        "| registered | num_registered_users\n",
        "| season | season_num\n",
        "| holiday | is_holiday\n",
        "| workingday | is_workingday\n",
        "| humidity | humidity_percent\n",
        "\n",
        "Without having to check, these new names make it obvious what is stored in each column. The downside is slightly longer column names, which could affect table readability in Jupyter. It would be ideal to use very specific names in CSV files to assist others reading them. In your own code, use whatever makes sense for your work -- if you are viewing lots of Pandas tables, you may want to use shorter names. However, readable specific names are preferred in Python code since it prevents mistakes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6OrcuVy11rt"
      },
      "outputs": [],
      "source": [
        "# Use the .rename() method to rename count to total\n",
        "bikes.rename({'count':'total_rentals'}, axis=1, inplace=True)\n",
        "bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHCVjWl111ru"
      },
      "source": [
        "<a id=\"visualizing-the-data\"></a>\n",
        "### Visualizing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CSr2PRn11ru"
      },
      "source": [
        "It is important to have a general feeling for what the data looks like before building a model. Ideally, before creating the model you would have some sense of which variables might matter most to predict the response. This dataset is fairly intuitive (and the purpose of this lesson is not visualization), so we will keep the visualization short."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwzcLISQ11ru"
      },
      "outputs": [],
      "source": [
        "# Pandas scatterplot\n",
        "bikes.plot(kind='scatter', x='temp', y='total_rentals', alpha=0.2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVAoxm8L11rv"
      },
      "outputs": [],
      "source": [
        "# Seaborn scatterplot with regression line\n",
        "sns.lmplot(x='temp', y='total_rentals', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgWlzF311rv"
      },
      "source": [
        "<a id=\"linear-regression-basics\"></a>\n",
        "## Linear Regression Basics\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_QZZNlu11rv"
      },
      "source": [
        "<a id=\"form-of-linear-regression\"></a>\n",
        "### Form of Linear Regression\n",
        "\n",
        "Recall that each model always contains some amount of random irreducible error $\\epsilon$. So, given a prediction $\\hat{y}$, the actual $y = \\hat{y} + \\epsilon$. Below, we will assume $y$ is exactly linear.\n",
        "\n",
        "- We are often taught the formula for a line is: $y = mx + b$.\n",
        "- Note this can alternatively be written: $y = \\alpha + \\beta X$.\n",
        "\n",
        "---\n",
        "\n",
        "Here, we will generalize this to $n$ independent variables as follows:\n",
        "\n",
        "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon$\n",
        "\n",
        "- $y$ is the response.\n",
        "- $\\beta_0$ is the intercept.\n",
        "- $\\beta_1$ is the coefficient for $x_1$ (the first feature).\n",
        "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature).\n",
        "- $\\epsilon$ is the _error_ term\n",
        "\n",
        "A practical example of this applied to our data might be:\n",
        "\n",
        "$total\\_rides = 20 + -2 \\cdot temp + -3 \\cdot windspeed\\ +\\ ...\\ +\\ 0.1 \\cdot registered$\n",
        "\n",
        "This equation is still called **linear** because the highest degree of the independent variables (e.g. $x_i$) is 1. Note that because the $\\beta$ values are constants, they will not be independent variables in the final model, as seen above.\n",
        "\n",
        "---\n",
        "\n",
        "The $\\beta$ values are called the **model coefficients**:\n",
        "\n",
        "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
        "- Specifically, we are trying to find the line (mathematically) that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
        "- Once we've learned these coefficients, we can use the model to predict the response.\n",
        "\n",
        "![Estimating coefficients](./images/estimating_coefficients.png)\n",
        "\n",
        "In the diagram above:\n",
        "\n",
        "- The black dots are the **observed values** of x and y.\n",
        "- The blue line is our **least squares line**.\n",
        "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UOJ-A611rw"
      },
      "source": [
        "# Finding the mimimal error\n",
        "\n",
        "<img src=\"https://www.dropbox.com/scl/fi/cg6zabqqsujvkrf1dq18u/gradient.gif?rlkey=j99cr71n8ib3bmibe4ceut4ey&raw=1\"  align=\"center\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nngPyVby11rw"
      },
      "source": [
        "<a id=\"overview-of-supervised-learning\"></a>\n",
        "## Overview of Supervised Learning\n",
        "---\n",
        "\n",
        "![Supervised learning diagram](./images/supervised_learning.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDYgQhfz11rw"
      },
      "source": [
        "<a id=\"requirements-for-working-with-data-in-scikit-learn\"></a>\n",
        "### Requirements for Working With Data in scikit-learn\n",
        "\n",
        "1. Features and response should be separate objects.\n",
        "2. Features and response should be entirely numeric.\n",
        "3. Features and response should be NumPy arrays (or easily converted to NumPy arrays).\n",
        "4. Features and response should have specific shapes (outlined below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H8w4GzW11rw"
      },
      "source": [
        "<a id=\"building-a-linear-regression-model-in-sklearn\"></a>\n",
        "## Building a Linear Regression Model in sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkr_pD8L11rw"
      },
      "source": [
        "#### Create a feature matrix called X that holds a `DataFrame` with only the temp variable and a `Series` called y that has the \"total_rentals\" column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPgyNyyF11rx"
      },
      "outputs": [],
      "source": [
        "# Create X and y.\n",
        "feature_cols = ['temp']\n",
        "X = bikes[feature_cols]\n",
        "y = bikes.total_rentals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbWF_fg911rx"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA20mC8911rx"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isWAMYPu11ry"
      },
      "outputs": [],
      "source": [
        "# Check X's type.\n",
        "print((type(X)))\n",
        "print((type(X.values)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBEbGenX11ry"
      },
      "outputs": [],
      "source": [
        "# Check y's type.\n",
        "print((type(y)))\n",
        "print((type(y.values)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "027y-XtJ11ry"
      },
      "outputs": [],
      "source": [
        "# Check X's shape (n = number of observations, p = number of features).\n",
        "print((X.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgOG9lz811rz"
      },
      "outputs": [],
      "source": [
        "# Check y's shape (single dimension with length n).\n",
        "# The comma indicates the datatype is a tuple.\n",
        "print((y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdHoEFUk11rz"
      },
      "source": [
        "-----\n",
        "<a id=\"scikit-learns--step-modeling-pattern\"></a>\n",
        "# scikit-learn's Four-Step Modeling Pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cicCqy211rz"
      },
      "source": [
        "**Step 1:** Import the class you plan to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yau8qdxX11rz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luyMTPlw11r0"
      },
      "source": [
        "**Step 2:** \"Instantiate\" the \"estimator.\"\n",
        "\n",
        "- \"Estimator\" is scikit-learn's term for \"model.\"\n",
        "- \"Instantiate\" means \"make an instance of.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQMQY6qQ11r0"
      },
      "outputs": [],
      "source": [
        "# Make an instance of a LinearRegression object.\n",
        "lr = LinearRegression()\n",
        "type(lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR2HESMj11r0"
      },
      "source": [
        "- Created an object that \"knows\" how to do linear regression, and is just waiting for data.\n",
        "- Name of the object does not matter.\n",
        "- All parameters not specified are set to their defaults.\n",
        "- Can specify tuning parameters (aka \"hyperparameters\") during this step.\n",
        "\n",
        "To view the possible parameters, either use the `help` built-in function or evaluate the newly instantiated model, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFWj8qtu11r0"
      },
      "outputs": [],
      "source": [
        "# help(lr)\n",
        "lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBWYGbtX11r1"
      },
      "source": [
        "**Step 3:** Fit the model with data (aka \"model training\").\n",
        "\n",
        "- Model is \"learning\" the relationship between X and y in our \"training data.\"\n",
        "- Process through which learning occurs varies by model.\n",
        "- Occurs in-place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9QhU3ZY11r1"
      },
      "outputs": [],
      "source": [
        "lr.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nogdl0R911r1"
      },
      "source": [
        "- Once a model has been fit with data, it's called a \"fitted model.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBqdHLCg11r1"
      },
      "source": [
        "**Step 4:** Predict the response for a new observation.\n",
        "\n",
        "- New observations are called \"out-of-sample\" data.\n",
        "- Uses the information it learned during the model training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z397fuVy11r1"
      },
      "outputs": [],
      "source": [
        "lr.predict([[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkMDFO1N11r2"
      },
      "outputs": [],
      "source": [
        "# Per future warning, one-dimensional arrays must be reshaped using the following.\n",
        "lr.predict(np.array([0,15,20,4]).reshape(4,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj0rsd1y11r2"
      },
      "outputs": [],
      "source": [
        "np.array([0,15,20,4]).reshape(4,-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWIJT3XD11r2"
      },
      "source": [
        "Let's ask the model to make two predictions, one when the `temp` is 0 and another when the `temp` is 10. To do this, our feature matrix is always a 2-D array where each row is a list of features. Since we only have a single feature, the temperature, each row will contain only a single value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dycyjc011r2"
      },
      "outputs": [],
      "source": [
        "## Fill such that you make 2 predictions for temp 0 and 10\n",
        "X_new = np.array([0,10]).reshape(-1,1)\n",
        "lr.predict(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhyafF0H11r3"
      },
      "source": [
        "- Returns a NumPy array, and we keep track of what the numbers \"mean.\"\n",
        "- Can predict for multiple observations at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6JQoEmv11r3"
      },
      "source": [
        "What we just predicted using our model is, \"If the temperature is 0 degrees, the total number of bike rentals will be ~6.046, and if the temperature is 10 degrees the total number of bike rentals will ~97.751.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iIrkgdy11r3"
      },
      "source": [
        "<a id=\"build-a-linear-regression-model\"></a>\n",
        "## Build a Linear Regression Model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9J_Fk0c11r3"
      },
      "source": [
        "Let's specifically make a linear regression model and look at the intercept and coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUyoXDEu11r4"
      },
      "source": [
        "#### Instantiate and fit a `LinearRegression` model on X and y from the `linear_model` section of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVTe19L_11r4"
      },
      "outputs": [],
      "source": [
        "# Import, instantiate, fit.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXpIhQFe11r4"
      },
      "outputs": [],
      "source": [
        "# Print the coefficients.\n",
        "print(linreg.intercept_)\n",
        "print(linreg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIQ0UIdE11r4"
      },
      "source": [
        "Interpreting the intercept ($\\beta_0$):\n",
        "\n",
        "- It is the value of $y$ when all independent variables are 0.\n",
        "- Here, it is the estimated number of rentals when the temperature is 0 degrees Celsius.\n",
        "- **Note:** It does not always make sense to interpret the intercept. (Why?)\n",
        "\n",
        "Interpreting the \"temp\" coefficient ($\\beta_1$):\n",
        "\n",
        "- **Interpretation:** An increase of 1 degree Celcius is _associated with_ increasing the number of total rentals by $\\beta_1$.\n",
        "- Here, a temperature increase of 1 degree Celsius is _associated with_ a rental increase of 9.17 bikes.\n",
        "- This is not a statement of causation.\n",
        "- $\\beta_1$ would be **negative** if an increase in temperature was associated with a **decrease** in total rentals.\n",
        "- $\\beta_1$ would be **zero** if temperature is not associated with total rentals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roq4pqTf11r4"
      },
      "source": [
        "<a id=\"using-the-model-for-prediction\"></a>\n",
        "## Using the Model for Prediction\n",
        "\n",
        "<img src=\"https://www.dropbox.com/scl/fi/siolwoelintawbmupln2r/predictions.png?rlkey=ar0hpulvnfus825cut60p7j0z&raw=1\"  align=\"center\"/>\n",
        "\n",
        "---\n",
        "\n",
        "While plenty of insight can be found in reading coefficients, the most common uses of data science focus on prediction. In scikit-learn we can make predictions from a fitted model using `.predict()`, but we will also go through the calculation by hand to understand it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkii98db11r5"
      },
      "source": [
        "#### How many bike rentals would we predict if the temperature was 25 degrees Celsius?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMDtquX11r5"
      },
      "source": [
        "#### Explore the intercept and coefficients of the linear model.\n",
        "\n",
        "You can search for \"sklearn linear regression\" and explore the attributes section of the documentation to learn how to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQjoTU6P11r5"
      },
      "outputs": [],
      "source": [
        "# Manually calculate the prediction.\n",
        "#temp 25\n",
        "6.04621295961681+(9.17054048*25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur-AvhjJ11r5"
      },
      "outputs": [],
      "source": [
        "# Use the predict method.\n",
        "lr.predict([[25]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqULoAQ711r6"
      },
      "source": [
        "<a id=\"does-the-scale-of-the-features-matter\"></a>\n",
        "### Does the Scale of the Features Matter?\n",
        "\n",
        "Let's say that temperature was measured in Fahrenheit, rather than Celsius. How would that affect the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDmHhyzJ11r6"
      },
      "outputs": [],
      "source": [
        "# Create a new column for Fahrenheit temperature.\n",
        "bikes['temp_F'] = bikes.temp * 1.8 + 32\n",
        "bikes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhocmn9x11r6"
      },
      "outputs": [],
      "source": [
        "# Seaborn scatterplot with regression line\n",
        "sns.lmplot(x='temp_F', y='total_rentals', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZSfRy_C11r6"
      },
      "source": [
        "#### Rebuild the `LinearRegression` from above using the `temp_F` features instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6qI3Pni11r6"
      },
      "outputs": [],
      "source": [
        "# Create X and y.\n",
        "feature_cols = ['temp_F']\n",
        "X = bikes[feature_cols]\n",
        "y = bikes.total_rentals\n",
        "\n",
        "# Instantiate and fit.\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)\n",
        "\n",
        "# Print the coefficients.\n",
        "print(linreg.intercept_)\n",
        "print(linreg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKuSncrL11r7"
      },
      "source": [
        "#### Convert 25 degrees Celsius to Fahrenheit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EPvJj_W11r7"
      },
      "outputs": [],
      "source": [
        "25 * 1.8 + 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3dNIpUy11r9"
      },
      "source": [
        "#### Predict rentals for 77 degrees Fahrenheit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lnjie6H11r9"
      },
      "outputs": [],
      "source": [
        "linreg.predict([[77]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlxKrKG11r9"
      },
      "source": [
        "**Conclusion:** The scale of the features is irrelevant for linear regression models. When changing the scale, we simply change our interpretation of the coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag_nSR9F11r9"
      },
      "outputs": [],
      "source": [
        "# Remove the temp_F column.\n",
        "bikes.drop('temp_F', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WenUFpDT11r9"
      },
      "source": [
        "<a id=\"work-with-multiple-features\"></a>\n",
        "## Work With Multiple Features\n",
        "---\n",
        "\n",
        "We've demonstrated simple linear regression with one feature to gain an intuition, but the benefit of modeling is the ability to reason about hundreds of features at once. There is no limit to the number of features you can use. However, often a small set of features accounts for most of the variance (assuming there is a linear relationship at all). We will start by using four features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqELf5PG11r-"
      },
      "source": [
        "<a id=\"visualizing-the-data-part-\"></a>\n",
        "### Visualizing the Data (Part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQtlsC-a11r-"
      },
      "source": [
        "#### Explore more features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSEtM1sO11r-"
      },
      "outputs": [],
      "source": [
        "# Create feature column variables\n",
        "feature_cols = ['temp', 'season', 'weather', 'humidity']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Kgqsoi11r-"
      },
      "source": [
        "#### Create a subset of scatterplot matrix using Seaborn.\n",
        "We can use pairplot with the y_vars argument to only show relationships with the `total_rentals` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ANfgcEp11r_"
      },
      "outputs": [],
      "source": [
        "# multiple scatterplots in Seaborn\n",
        "sns.pairplot(bikes, x_vars=feature_cols, y_vars='total_rentals', kind='reg');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lqjDY3-11r_"
      },
      "source": [
        "#### Recreate the same functionality using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZpPsgHN11r_"
      },
      "outputs": [],
      "source": [
        "# Multiple scatterplots in Pandas\n",
        "fig, axs = plt.subplots(1, len(feature_cols), sharey=True)\n",
        "for index, feature in enumerate(feature_cols):\n",
        "    bikes.plot(kind='scatter', x=feature, y='total_rentals', ax=axs[index], figsize=(16, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAR7Ng-u11r_"
      },
      "outputs": [],
      "source": [
        "# alternative way in Pandas (might take a while)\n",
        "# scatter_matrix does a pairplot of *every* column\n",
        "\n",
        "grr = pd.plotting.scatter_matrix(bikes[['total_rentals'] + feature_cols], figsize=(15, 15), alpha=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgjX2n1H11sA"
      },
      "source": [
        "#### Are you seeing anything you didn't expect?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6C-xPWb11sA"
      },
      "source": [
        "#### Explore the season variable using a cross-tab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwKlcC2X11sA"
      },
      "outputs": [],
      "source": [
        "# Cross-tabulation of season and month\n",
        "pd.crosstab(bikes.season, bikes.index.month)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-zFp_l11sA"
      },
      "source": [
        "#### Explore the season variable using a box plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1jznjh811sB"
      },
      "outputs": [],
      "source": [
        "# Box plot of rentals, grouped by season\n",
        "bikes.boxplot(column='total_rentals', by='season');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-4Vsd9511sB"
      },
      "source": [
        "Notably:\n",
        "\n",
        "- A line can't capture a nonlinear relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od-Uf6k111sB"
      },
      "source": [
        "#### Look at rentals over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSWcU01h11sC"
      },
      "outputs": [],
      "source": [
        "# Line plot of rentals\n",
        "bikes.total_rentals.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIINt3ML11sC"
      },
      "source": [
        "#### What does this tell us?\n",
        "\n",
        "There are more rentals in the winter than the spring, but only because the system is experiencing overall growth and the winter months happen to come after the spring months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEg__lG11sC"
      },
      "source": [
        "#### Look at the correlation matrix for the bikes `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfQ7TLp711sC"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix (ranges from 1 to -1)\n",
        "bikes.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68AXR3z511sD"
      },
      "source": [
        "#### Use a heat map to make it easier to read the correlation matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_pFvUDf11sD"
      },
      "outputs": [],
      "source": [
        "# Visualize correlation matrix in Seaborn using a heat map.\n",
        "sns.heatmap(bikes.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIn30FDe11sD"
      },
      "source": [
        "#### What relationships do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q2oKMPW11sE"
      },
      "outputs": [],
      "source": [
        "# A:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ya82f9_11sE"
      },
      "source": [
        "<a id=\"adding-more-features-to-the-model\"></a>\n",
        "### Adding More Features to the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Z8WYtY11sF"
      },
      "source": [
        "In the previous example, one variable explained the variance of another; however, more often than not, we will need multiple variables.\n",
        "\n",
        "- For example, a house's price may be best measured by square feet, but a lot of other variables play a vital role: bedrooms, bathrooms, location, appliances, etc.\n",
        "\n",
        "- For a linear regression, we want these variables to be largely independent of one another, but all of them should help explain the y variable.\n",
        "\n",
        "We'll work with bikeshare data to showcase what this means and to explain a concept called multicollinearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqzUvyLq11sF"
      },
      "source": [
        "#### Create another `LinearRegression` instance that is fit using temp, season, weather, and humidity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU3LpCnL11sF"
      },
      "outputs": [],
      "source": [
        "# Create a list of features.\n",
        "feature_cols = ['temp', 'season', 'weather', 'humidity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB0x_lbv11sF"
      },
      "outputs": [],
      "source": [
        "# Create X and y.\n",
        "X = bikes[feature_cols]\n",
        "y = bikes.total_rentals\n",
        "\n",
        "# Instantiate and fit.\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)\n",
        "\n",
        "# Print the coefficients.\n",
        "print(linreg.intercept_)\n",
        "print(linreg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91U6pNL411sG"
      },
      "source": [
        "#### Display the linear regression coefficient along with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbvZqnV811sG"
      },
      "outputs": [],
      "source": [
        "# Pair the feature names with the coefficients.\n",
        "list(zip(feature_cols, linreg.coef_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgGRjeMH11sG"
      },
      "source": [
        "Interpreting the coefficients:\n",
        "\n",
        "- Holding all other features fixed, a 1-unit increase in temperature is associated with a rental increase of 7.86 bikes.\n",
        "- Holding all other features fixed, a 1-unit increase in season is associated with a rental increase of 22.5 bikes.\n",
        "- Holding all other features fixed, a 1-unit increase in weather is associated with a rental increase of 6.67 bikes.\n",
        "- Holding all other features fixed, a 1-unit increase in humidity is associated with a rental decrease of 3.12 bikes.\n",
        "\n",
        "Does anything look incorrect and does not reflect reality?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYNPfXlV11sG"
      },
      "source": [
        "# Try new feature combinations and anlyze the coefficients\n",
        "<img src=\"https://www.dropbox.com/scl/fi/76r2mea69m6mdinnaqweh/hands_on.jpg?rlkey=bchhotvwfjzgb7hc35igxxphs&raw=1\" width=\"100\" height=\"100\" align=\"right\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6uJW7oo11sH"
      },
      "outputs": [],
      "source": [
        "# type your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnPzKKT111sH"
      },
      "source": [
        "<a id=\"what-is-multicollinearity\"></a>\n",
        "## What Is Multicollinearity?\n",
        "---\n",
        "\n",
        "Multicollinearity happens when two or more features are highly correlated with each other. The problem is that due to the high correlation, it's hard to disambiguate which feature has what kind of effect on the outcome. In other words, the features mask each other.\n",
        "\n",
        "There is a second related issue called variance inflation where including correlated features increases the variability of our model and p-values by widening the standard errors. This can be measured with the variance inflation factor, which we will not cover here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jdZXKFT11sH"
      },
      "outputs": [],
      "source": [
        "bikes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYQ_o0r11sH"
      },
      "source": [
        "#### With the bikeshare data, let's compare three data points: actual temperature, \"feel\" temperature, and guest ridership."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv_Y30Sp11sI"
      },
      "outputs": [],
      "source": [
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "correlations = bikes[['temp', 'atemp', 'casual']].corr()\n",
        "print(correlations)\n",
        "print(sns.heatmap(correlations, cmap=cmap))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba6ETsf011sJ"
      },
      "source": [
        "#### Create a linear model that predicts `total_rentals` using `temp` and `atemp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Q11k5u11sJ"
      },
      "outputs": [],
      "source": [
        "# Create a list of features.\n",
        "feature_cols = ['atemp', 'temp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdDn33QO11sJ"
      },
      "outputs": [],
      "source": [
        "# Create X and y.\n",
        "X = bikes[feature_cols]\n",
        "y = bikes.total_rentals\n",
        "\n",
        "# Instantiate and fit.\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)\n",
        "\n",
        "# Print the coefficients.\n",
        "print(linreg.intercept_)\n",
        "print(linreg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwS0_aRa11sK"
      },
      "source": [
        "#### Go back and remove either `temp` or `atemp` from the feature list. How do the coefficients change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aunuK-9e11sK"
      },
      "outputs": [],
      "source": [
        "# A:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rZ7KgzB11sK"
      },
      "source": [
        "<a id=\"how-to-select-a-model\"></a>\n",
        "## How to Select a Model\n",
        "---\n",
        "\n",
        "We can make linear models now, but how do we select the best model to use for our applications? We will offer a general procedure and a simple metric that works well in many cases. That said, it's important to keep the business context in mind and know that there are alternative metrics that can work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tibT7Q_b11sK"
      },
      "source": [
        "<a id=\"feature-selection\"></a>\n",
        "### Feature Selection\n",
        "\n",
        "How do we choose which features to include in the model? We're going to use **train/test split** (and eventually **cross-validation**).\n",
        "\n",
        "Why not use p-values or R-squared for feature selection?\n",
        "\n",
        "- Linear models rely upon a lot of assumptions (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train/test split relies on fewer assumptions.\n",
        "- If all of the assumptions of a linear model are met, p-values suggest a coefficient that differs from zero at a level of statistical significance. This does not mean that\n",
        "    1. the feature _causes_ the response\n",
        "    2. the feature strongly _predicts_ the response.\n",
        "- Adding features to your model that are unrelated to the response will always increase the R-squared value, and adjusted R-squared does not sufficiently account for this (although, AIC and BIC do).\n",
        "- p-values and R-squared are **proxies** for our goal of generalization, whereas train/test split and cross-validation attempt to directly estimate how well the model will generalize to out-of-sample data.\n",
        "\n",
        "More generally:\n",
        "\n",
        "- There are different methodologies that can be used for solving any given data science problem, and this course follows a machine learning methodology.\n",
        "- This course focuses on general purpose approaches that can be applied to any model, rather than model-specific approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HKH-Eln11sK"
      },
      "source": [
        "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
        "### Evaluation Metrics for Regression Problems\n",
        "\n",
        "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. We need evaluation metrics designed for comparing continuous values.\n",
        "\n",
        "Here are three common evaluation metrics for regression problems:\n",
        "\n",
        "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
        "\n",
        "**Mean squared error (MSE)** is the mean of the squared errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
        "\n",
        "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAGJi8CE11sK"
      },
      "outputs": [],
      "source": [
        "# Example true and predicted response values\n",
        "true = [10, 7, 5, 5]\n",
        "pred = [8, 6, 5, 10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZo9kyF111sK"
      },
      "source": [
        "#### Calculate MAE, MSE, and RMSE using imports from sklearn metrics and NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mcnvmrm11sK"
      },
      "outputs": [],
      "source": [
        "# Calculate these metrics by hand!\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
        "print('MSE:', metrics.mean_squared_error(true, pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHC5-CsH11sK"
      },
      "source": [
        "Let's compare these metrics:\n",
        "\n",
        "- MAE is the easiest to understand, because it's the average error.\n",
        "- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world. Also, MSE is continuous and differentiable, making it easier to use than MAE for optimization.\n",
        "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "\n",
        "All of these are **loss functions**, because we want to minimize them.\n",
        "\n",
        "Here's an additional example, to demonstrate how MSE/RMSE punishes larger errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRmwld1511sK"
      },
      "outputs": [],
      "source": [
        "# Same true values as above\n",
        "true = [10, 7, 5, 5]\n",
        "\n",
        "# New set of predicted values\n",
        "pred = [10, 7, 5, 13]\n",
        "\n",
        "# MAE is the same as before.\n",
        "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
        "\n",
        "# MSE and RMSE are larger than before.\n",
        "print('MSE:', metrics.mean_squared_error(true, pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5XQNv-011sK"
      },
      "source": [
        "<a id=\"comparing-models-with-traintest-split-and-rmse\"></a>\n",
        "### Comparing Models With Train/Test Split and RMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87LtKMPk11sL"
      },
      "source": [
        "<img src=\"https://www.dropbox.com/scl/fi/utt43l2tqplsr50f0ta1t/train_test_split.svg?rlkey=mjsaxpv9g8cbaeo9a70iilajo&raw=1\"  align=\"center\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54I9dNnw11sL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a function that accepts a list of features and returns testing RMSE. Use train_test_split emthod to split\n",
        "def train_test_rmse(df, feature_cols):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpA9BTcM11sL"
      },
      "outputs": [],
      "source": [
        "# Compare different sets of features.\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'weather', 'humidity']))\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'weather']))\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'humidity']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzRu4l_P11sL"
      },
      "outputs": [],
      "source": [
        "# Using these as features is not allowed!\n",
        "print(train_test_rmse(bikes, ['casual', 'registered']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwEV3NT11sM"
      },
      "source": [
        "<a id=\"feature-engineering-to-improve-performance\"></a>\n",
        "## Feature Engineering to Improve Performance\n",
        "\n",
        "<img src=\"https://www.dropbox.com/scl/fi/81y448bnm37equ5c6wabm/feature-engineering.jpg?rlkey=u2lkempxbjj7res5wpgpyh4w0&raw=1\" align=\"right\"/>\n",
        "\n",
        "---\n",
        "\n",
        "Machine learning models are very powerful, but they cannot automatically handle every aspect of our data. We have to explicitly modify our features to have relationships that our models can understand. In this case, we will need to pull out features to have a linear relationship with our response variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mooc2FSw11sM"
      },
      "source": [
        "<a id=\"handling-categorical-features\"></a>\n",
        "### Handling Categorical Features\n",
        "\n",
        "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
        "\n",
        "- **Ordered categories:** Transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
        "- **Unordered categories:** Use dummy encoding (0/1). Here, each possible category would become a separate feature.\n",
        "\n",
        "What are the categorical features in our data set?\n",
        "\n",
        "- **Ordered categories:** `weather` (already encoded with sensible numeric values)\n",
        "- **Unordered categories:** `season` (needs dummy encoding), `holiday` (already dummy encoded), `workingday` (already dummy encoded)\n",
        "\n",
        "For season, we can't simply leave the encoding as 1 = spring, 2 = summer, 3 = fall, and 4 = winter, because that would imply an ordered relationship. Instead, we create multiple dummy variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzyaqlhY11sM"
      },
      "outputs": [],
      "source": [
        "bikes.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5QdHjrE11sM"
      },
      "source": [
        "#### Create dummy variables using `get_dummies` from Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tNX2W4D11sM"
      },
      "outputs": [],
      "source": [
        "season_dummies = pd.get_dummies(bikes.season, prefix='season')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LrkvqwB11sM"
      },
      "source": [
        "#### Inspect the `DataFrame` of `dummies`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLBs5nhU11sN"
      },
      "outputs": [],
      "source": [
        "# Print five random rows.\n",
        "season_dummies.sample(n=5, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdAW-5QW11sN"
      },
      "source": [
        "#### Reinspect the `DataFrame` of `dummies`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8JBQveP11sN"
      },
      "outputs": [],
      "source": [
        "# Print five random rows.\n",
        "season_dummies.sample(n=5, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T72mWaLe11sO"
      },
      "source": [
        "#### We now need to concatenate the two `DataFrames` together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce_7DyY011sO"
      },
      "outputs": [],
      "source": [
        "# Concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns).\n",
        "bikes_dummies = pd.concat([bikes, season_dummies], axis=1)\n",
        "\n",
        "# Print 5 random rows.\n",
        "bikes_dummies.sample(n=5, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mb_SFOM11sO"
      },
      "source": [
        "#### Rerun the linear regression with dummy variables included."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yT5xUCM11sO"
      },
      "outputs": [],
      "source": [
        "# Include dummy variables for season in the model.\n",
        "feature_cols = ['temp','season_1', 'season_2', 'season_3', 'season_4', 'humidity']\n",
        "X = bikes_dummies[feature_cols]\n",
        "y = bikes_dummies.total_rentals\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)\n",
        "\n",
        "list(zip(feature_cols, linreg.coef_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDOO2k8D11sP"
      },
      "source": [
        "How do we interpret the season coefficients? They are measured against the baseline (spring):\n",
        "\n",
        "- Holding all other features fixed, summer is associated with a rental decrease of 3.39 bikes compared to the spring.\n",
        "- Holding all other features fixed, fall is associated with a rental decrease of 41.7 bikes compared to the spring.\n",
        "- Holding all other features fixed, winter is associated with a rental increase of 64.4 bikes compared to the spring.\n",
        "\n",
        "Would it matter if we changed which season was defined as the baseline?\n",
        "\n",
        "- No, it would simply change our interpretation of the coefficients.\n",
        "\n",
        "In most situations, it is best to have the dummy that is your baseline be the category that has the largest representation.\n",
        "\n",
        "**Important:** Dummy encoding is relevant for all machine learning models, not just linear regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEj9pwsW11sP"
      },
      "outputs": [],
      "source": [
        "# Compare original season variable with dummy variables.\n",
        "print(train_test_rmse(bikes_dummies, ['temp', 'season', 'humidity']))\n",
        "print(train_test_rmse(bikes_dummies, ['temp','season_1', 'season_2', 'season_3', 'season_4', 'humidity']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYP0l6RP11sP"
      },
      "source": [
        "<a id=\"feature-engineering\"></a>\n",
        "## More Feature Engineering\n",
        "\n",
        "See if you can create the following features:\n",
        "\n",
        "- **hour:** as a single numeric feature (0 through 23)\n",
        "- **hour:** as a categorical feature (use 23 dummy variables)\n",
        "- **daytime:** as a single categorical feature (daytime=1 from 7 a.m. to 8 p.m., and daytime=0 otherwise)\n",
        "\n",
        "Then, try using each of the three features (on its own) with `train_test_rmse` to see which one performs the best!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhM2xmMk11sP"
      },
      "outputs": [],
      "source": [
        "bikes.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPaQOQ6611sQ"
      },
      "source": [
        "#### Extract hour of the day to use as a feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HE7vvrU11sQ"
      },
      "outputs": [],
      "source": [
        "bikes['hour']=bikes.index.hour\n",
        "bikes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg4Zrhx711sQ"
      },
      "source": [
        "#### Test the root mean squared error of our various `hour` encodings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0y5W0nW11sQ"
      },
      "outputs": [],
      "source": [
        "print(train_test_rmse(bikes, ['temp', 'season', 'humidity']))\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'humidity','hour']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM7WwEL611sQ"
      },
      "outputs": [],
      "source": [
        "## Now do the same but with hour as categorical and daytime!\n",
        "hour_dummies = pd.get_dummies(bikes.hour, prefix='hour')\n",
        "hour_dummies = pd.concat([bikes, hour_dummies], axis=1)\n",
        "\n",
        "bikes[\"daytime_late\"] = bikes.hour < 19\n",
        "bikes[\"daytime_early\"] = bikes.hour > 7\n",
        "bikes[\"daytime\"] = bikes[\"daytime_late\"] & bikes[\"daytime_early\"]\n",
        "bikes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvG7NXlx11sR"
      },
      "outputs": [],
      "source": [
        "hours = []\n",
        "for i in range(24):\n",
        "    hours.extend(f\"hour_{i}\")\n",
        "print(train_test_rmse(hour_dummies, ['temp', 'season', 'humidity', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23']))\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'humidity','hour']))\n",
        "print(train_test_rmse(bikes, ['temp', 'season', 'humidity','daytime']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLyJYZta11sR"
      },
      "source": [
        "<a id=\"comparing-linear-regression-with-other-models\"></a>\n",
        "## Comparing Linear Regression With Other Models\n",
        "\n",
        "Advantages of linear regression:\n",
        "\n",
        "- Simple to explain.\n",
        "- Highly interpretable.\n",
        "- Model training and prediction are fast.\n",
        "- No tuning is required (excluding regularization).\n",
        "- Features don't need scaling.\n",
        "- Can perform well with a small number of observations.\n",
        "- Well understood.\n",
        "\n",
        "Disadvantages of linear regression:\n",
        "\n",
        "- Presumes a linear relationship between the features and the response.\n",
        "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
        "- Can't automatically learn feature interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFY6KIh811sR"
      },
      "source": [
        "# Now you do it\n",
        "<img src=\"https://www.dropbox.com/scl/fi/76r2mea69m6mdinnaqweh/hands_on.jpg?rlkey=bchhotvwfjzgb7hc35igxxphs&raw=1\" width=\"100\" height=\"100\" align=\"right\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z03zlwbX11sR"
      },
      "source": [
        "## Sacramento Real Estate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWf5B0wf11sS"
      },
      "source": [
        "### Goal: Perdict the Price of a house!\n",
        "\n",
        "- Just use numerical features for the prediction (beds, bath, sq_ft, latitude, longtitude)\n",
        "\n",
        "#### How?\n",
        "- Expolore the dataset\n",
        "- Clean it\n",
        "- Do Feature Engineering\n",
        "- Create nesseccary encodings\n",
        "- Build a regression model\n",
        "- Test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHQHjzdH11sS"
      },
      "outputs": [],
      "source": [
        "sac_csv = './data/sacramento.csv'\n",
        "sac=pd.read_csv(sac_csv)\n",
        "sac.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZaeTF0j11sS"
      },
      "outputs": [],
      "source": [
        "sac.city.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ouaDs6o11sT"
      },
      "outputs": [],
      "source": [
        "city_dummies = pd.get_dummies(sac.city, prefix='city')\n",
        "city_dummies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d24gxGKI11sT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}